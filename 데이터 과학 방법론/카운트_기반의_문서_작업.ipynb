{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP2kLFsSUy8I8F5MQJg2egW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yesyell/DA_School_1/blob/main/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EA%B3%BC%ED%95%99%20%EB%B0%A9%EB%B2%95%EB%A1%A0/%EC%B9%B4%EC%9A%B4%ED%8A%B8_%EA%B8%B0%EB%B0%98%EC%9D%98_%EB%AC%B8%EC%84%9C_%EC%9E%91%EC%97%85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "4rtGPA5_ar_O"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bow (Bag of words) 개념"
      ],
      "metadata": {
        "id": "pzSmc4mbZ4Sw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-izD9stZhZP",
        "outputId": "0c13ddc9-4404-41fc-9efc-e76f361aaddd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['개를', '고양이를', '나는', '좋아한다'], dtype=object),\n",
              " array([[0, 1, 1, 1],\n",
              "        [1, 0, 1, 1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# 예제 문장\n",
        "sentences = [\"나는 고양이를 좋아한다.\", \"나는 개를 좋아한다.\"]\n",
        "\n",
        "# CountVectorizer 객체 생성\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# 문장을 벡터로 변환\n",
        "X = vectorizer.fit_transform(sentences)\n",
        "\n",
        "# 결과 출력\n",
        "vocabulary = vectorizer.get_feature_names_out()\n",
        "vectors = X.toarray()\n",
        "\n",
        "vocabulary, vectors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 문장 4개 추가\n",
        "extended_sentences = [\n",
        "    \"나는 고양이를 좋아한다.\",\n",
        "    \"나는 개를 좋아한다.\",\n",
        "    \"고양이는 귀엽다.\",\n",
        "    \"개는 충성스럽다.\",\n",
        "    \"이것은 예제 문장이다.\"\n",
        "]\n",
        "\n",
        "# 문장을 벡터로 변환\n",
        "X_extended = vectorizer.fit_transform(extended_sentences)\n",
        "\n",
        "# 결과 출력\n",
        "extended_vocabulary = vectorizer.get_feature_names_out()\n",
        "extended_vectors = X_extended.toarray()\n",
        "\n",
        "# 결과를 하나의 리스트로 합치기\n",
        "combined_result = list(zip(extended_vocabulary, extended_vectors.sum(axis=0)))\n",
        "\n",
        "combined_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3xJyhUWZmfs",
        "outputId": "3b485708-811a-472b-b3c6-23b3162bd5cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('개는', 1),\n",
              " ('개를', 1),\n",
              " ('고양이는', 1),\n",
              " ('고양이를', 1),\n",
              " ('귀엽다', 1),\n",
              " ('나는', 2),\n",
              " ('문장이다', 1),\n",
              " ('예제', 1),\n",
              " ('이것은', 1),\n",
              " ('좋아한다', 2),\n",
              " ('충성스럽다', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMDB 리뷰 데이터"
      ],
      "metadata": {
        "id": "EfreUP0jfe9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeWUyyPvj2or",
        "outputId": "d29b99d1-af9d-4f39-bdb4-34a1342e602f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.datasets import imdb\n",
        "\n",
        "# (train_input, train_target), (test_input, test_target) = imdb.load_data(\n",
        "#     num_words=500)\n",
        "\n",
        "# print(train_input.shape, test_input.shape)"
      ],
      "metadata": {
        "id": "R5E2pLwFfN5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드 (예시: IMDB 영화 리뷰 데이터)\n",
        "data = pd.read_csv('/content/IMDB Dataset.csv')\n",
        "reviews = data['review']\n",
        "sentiments = data['sentiment']"
      ],
      "metadata": {
        "id": "biAY8Q2Ubcxy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리 (토큰화, 불용어 제거 등)\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def preprocess(text):\n",
        "    # HTML 태그 제거\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    # 숫자와 특수문자 제거\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # 소문자 변환 및 토큰화\n",
        "    words = text.lower().split()\n",
        "    # 불용어 제거\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# 리뷰 전처리\n",
        "reviews = reviews.apply(preprocess)"
      ],
      "metadata": {
        "id": "qH3BCxbPbh7g"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxOW3tQUCpBA",
        "outputId": "add33a84-9125-49dd-c2b4-67fb8cf4baaa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        one reviewers mentioned watching oz episode yo...\n",
              "1        wonderful little production filming technique ...\n",
              "2        thought wonderful way spend time hot summer we...\n",
              "3        basically theres family little boy jake thinks...\n",
              "4        petter matteis love time money visually stunni...\n",
              "                               ...                        \n",
              "49995    thought movie right good job wasnt creative or...\n",
              "49996    bad plot bad dialogue bad acting idiotic direc...\n",
              "49997    catholic taught parochial elementary schools n...\n",
              "49998    im going disagree previous comment side maltin...\n",
              "49999    one expects star trek movies high art fans exp...\n",
              "Name: review, Length: 50000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bow"
      ],
      "metadata": {
        "id": "hMqw575nnLet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_bow = CountVectorizer(max_features=5000)\n",
        "X_bow = vectorizer_bow.fit_transform(reviews)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_bow, sentiments, test_size=0.2, random_state=42)\n",
        "\n",
        "model_bow = LogisticRegression()\n",
        "model_bow.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model_bow.predict(X_test)\n",
        "print(\"Bag of Words Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01fgPYy5nMnh",
        "outputId": "4c4e619a-cc4b-4d10-8d1d-d46ccc15ff4e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words Accuracy: 0.874\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.88      0.87      0.87      4961\n",
            "    positive       0.87      0.88      0.88      5039\n",
            "\n",
            "    accuracy                           0.87     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.87      0.87      0.87     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF"
      ],
      "metadata": {
        "id": "FlC2mce8mJ4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF 변환기를 사용하여 텍스트를 벡터로 변환\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "X = vectorizer.fit_transform(reviews)\n",
        "y = sentiments\n",
        "\n",
        "# 학습 및 테스트 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 로지스틱 회귀 모델 학습\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 예측 및 평가\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"TF-IDF Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82THvwIGbndc",
        "outputId": "f3a9d8bd-ad19-4090-e9e6-a47645b76e20"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Accuracy: 0.8867\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.90      0.87      0.88      4961\n",
            "    positive       0.88      0.90      0.89      5039\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Embedding (Word2Vec)"
      ],
      "metadata": {
        "id": "UhyrrFWVbf0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Word2Vec 모델 학습\n",
        "model = gensim.models.Word2Vec(sentences=reviews, vector_size=100,\n",
        "                               window=5, min_count=5, workers=4)\n",
        "\n",
        "# 단어 벡터의 평균으로 리뷰를 벡터로 변환\n",
        "def get_vector(review):\n",
        "    vector = []\n",
        "    for word in review:\n",
        "        try:\n",
        "            vector.append(model.wv[word])\n",
        "        except KeyError:\n",
        "            pass\n",
        "    return np.mean(vector, axis=0)\n",
        "\n",
        "X = reviews.apply(get_vector)\n",
        "y = sentiments\n",
        "\n",
        "# 학습 및 테스트 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 로지스틱 회귀 모델 학습\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 예측 및 평가\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "5ttpi8ALEc5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMDB 영화 리뷰 데이터셋을 이용한 감성 분석에 대한 세 가지 텍스트 표현 방법 (Bag of Words, TF-IDF, Word2Vec)의 성능 비교를 했을 때의 결론은 다음과 같습니다:\n",
        "\n",
        "1. **성능 측면**:\n",
        "    - **Bag of Words**: 이 방식은 단순히 단어의 발생 빈도를 기반으로 하기 때문에, 문맥적 정보나 단어 간의 관계를 포착하지 못합니다. 따라서 성능이 다른 방법에 비해 낮을 수 있습니다.\n",
        "    - **TF-IDF**: Bag of Words에 비해 단어의 중요도를 고려하므로 성능 향상을 기대할 수 있습니다. 그러나 여전히 문맥 정보를 포착하지 못하는 단점이 있습니다.\n",
        "    - **Word2Vec**: 단어의 문맥적 정보와 의미를 잘 반영하여 벡터화하기 때문에, 보다 정확한 감성 분석 결과를 얻을 수 있습니다. 그러나 충분한 학습 데이터가 필요하며, 학습 시간이 길어질 수 있습니다.\n",
        "2. **기능 측면**:\n",
        "    - **Bag of Words와 TF-IDF**: 이 두 방법은 단어의 순서나 문맥 정보를 포착하지 못합니다. 그러나 구현이 간단하고 학습 속도가 빠르다는 장점이 있습니다.\n",
        "    - **Word2Vec**: 단어 간의 유사성이나 관계를 포착할 수 있기 때문에, 단순한 감성 분석 외에도 다양한 NLP 작업에 활용할 수 있습니다."
      ],
      "metadata": {
        "id": "3TzMZ897DP6-"
      }
    }
  ]
}